---
layout: page
title: Workshop Abstracts
description: Workshop Abstracts
permalink: /abstracts/
---

## Automating Onboarding: Empowering New Team Members through DevOps

_Caleb Jackson, Sandia National Laboratories_

The chief question this talk addresses is: how can the intersection of onboarding and DevOps benefit Research Software Engineers (RSEs) and their teams while fostering sustainability? Streamlining the onboarding process enables new team members to become productive more quickly and efficiently. Bridging the gap between early-career and seasoned professionals, this talk will demonstrate how DevOps nurtures an environment of continuous learning and adaptability. Embracing sustainable approaches ensures the longevity of software projects and supports the career growth of RSEs. This, in turn, contributes to the overall sustainability of their teams and project work.

Furthermore, this talk draws insights from personal experiences working on DevOps teams to explore methods for enhancing onboarding strategies through the incorporation of DevOps practices and automation of key aspects. Additionally, it delves into the core concept of documentation as code, a transformative approach that creates dynamic and living documentation, evolving in sync with the project. Furthermore, the talk will discuss the added value of including documentation in code reviews, amplifying the feedback loop, and improving knowledge transfer.

In summary, this talk provides practical suggestions to enhance common onboarding experiences by exploring the intersection of automation, documentation, and collaboration. By implementing the strategies shared in this talk, teams can foster a sustainable onboarding journey that empowers RSEs and their teams to thrive in the future.

------

## Energy-Efficient Neural Network Pruning for Environmentally-Friendly AI/ML

_Jamil Gafur, University of Iowa_

Neural networks have long been plagued by over-parameterization, leading to increased computational costs and energy consumption. Iterative Magnitude Pruning, an effective technique, has demonstrated the potential to reduce network parameters by 70% or more while maintaining comparable accuracy. Here, we investigate the impact of model pruning on interpretability, exploring how insights into the model change as we trim its size. Our study not only reveals the interpretability patterns during pruning but also underscores the intrinsic relationship between parameter size reduction and energy usage decrease. Considering AI/ML's substantial projected share of energy consumption in the USA (around 20% in 2030), our research advocates for the adoption of energy-efficient pruning methods, enabling us to cut energy costs while remaining environmentally conscious. By forging a link between interpretability and energy efficiency, this work lays the foundation for the development of more interpretable and sustainable AI/ML systems, fostering trust and accountability in their deployment.

------

## Towards Responsible AI/ML Systems: A Unified Framework with MLOP Workflow to Address Robustness, Interpretability, and Power Consumption (RIP) Concerns

_Jamil Gafur, University of Iowa_

Artificial Intelligence (AI) and Machine Learning (ML) models have witnessed remarkable growth and adoption across various domains due to their outstanding performance. However, concerns related to Robustness, Interpretability, and Power Consumption (RIPC) have surfaced as their usage increases. Addressing these issues is crucial for ensuring the effective and optimized functioning of AI/ML systems. Current ML operation (MLOP) workflows have proven insufficient in tackling these challenges, necessitating the development of comprehensive methodologies and frameworks. In this research, we propose a novel MLOP workflow that targets the resolution of RIPC concerns, complemented by a synergistic framework capitalizing on the interaction between algorithms to address each aspect concerning Neural Networks (NNs). Our primary objective is to devise a unified framework that not only enhances the interpretability, security, and energy efficiency of ML models but also fosters their responsible deployment, facilitating wider adoption of AI/ML technologies. Through this work, we aim to pave the way for more reliable and transparent AI/ML systems.
